{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f8UiFZhQdgC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import  GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import warnings\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIbsmsHlQgiD"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "print(\"Starting Anomaly Detection System Setup...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHLGTR3rQgfL"
      },
      "outputs": [],
      "source": [
        "print(\"Loading datasets...\")\n",
        "df1 = pd.read_csv('UNSW_NB15_training-set.csv')\n",
        "df2 = pd.read_csv('UNSW_NB15_testing-set.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydUJoNnnQgcN"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([df1, df2], ignore_index=True)\n",
        "print(\"Datasets loaded and concatenated. Total records:\", len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8Aw1MvjQgZa"
      },
      "outputs": [],
      "source": [
        "print(\"Dropping irrelevant columns: 'id' and 'attack_cat'\")\n",
        "df.drop(['id', 'attack_cat'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFZZRziRQgWH"
      },
      "outputs": [],
      "source": [
        "print(\"Clamping extreme values in numeric columns...\")\n",
        "df_numeric = df.select_dtypes(include=[np.number])\n",
        "for feature in df_numeric.columns:\n",
        "    if df[feature].max() > 10 * df[feature].median():\n",
        "        df[feature] = np.where(\n",
        "            df[feature] < df[feature].quantile(0.95),\n",
        "            df[feature],\n",
        "            df[feature].quantile(0.95)\n",
        "        )\n",
        "print(\"Clamping complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfHhXwRaQgTa"
      },
      "outputs": [],
      "source": [
        "print(\"Applying log transformation on skewed numeric features...\")\n",
        "for feature in df_numeric.columns:\n",
        "    if df[feature].nunique() > 50:\n",
        "        df[feature] = np.log1p(df[feature])\n",
        "print(\"Log transformation complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YeVTg3pQyf5"
      },
      "outputs": [],
      "source": [
        "print(\"Reducing cardinality of categorical features...\")\n",
        "df_cat = df.select_dtypes(exclude=[np.number])\n",
        "for feature in df_cat.columns:\n",
        "    top_labels = df[feature].value_counts().nlargest(5).index\n",
        "    df[feature] = df[feature].apply(lambda x: x if x in top_labels else '-')\n",
        "print(\"Categorical cardinality reduction done.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1hD5qssQ0MN"
      },
      "outputs": [],
      "source": [
        "print(\"Encoding categorical features using OneHotEncoder...\")\n",
        "X = df.drop('label', axis=1)\n",
        "y = df['label']\n",
        "cat_features = X.select_dtypes(include='object').columns\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5HCuu67Q3E_"
      },
      "outputs": [],
      "source": [
        "print(\"Splitting dataset into train and test sets...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "print(\"Data split complete:\")\n",
        "print(\"  Training samples:\", X_train.shape[0])\n",
        "print(\"  Testing samples:\", X_test.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXP0z-lMQ5bc"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myYrYIR9Q5V_"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=5, n_jobs=-1),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier()\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09YYhZFuQ5TJ"
      },
      "outputs": [],
      "source": [
        "# Training and evaluating models\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    print(\"\\n============================================\")\n",
        "    print(\"Training and Evaluating Model:\", name)\n",
        "    print(\"============================================\")\n",
        "    start_time = time.time()\n",
        "    pipeline = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('scaler', scaler),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    train_time = time.time() - start_time\n",
        "    print(f\"Training completed in {train_time:.2f} seconds\")\n",
        "\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    y_proba = pipeline.predict_proba(X_test) if hasattr(pipeline.named_steps['classifier'], 'predict_proba') else None\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    print(\"Confusion Matrix:\")\n",
        "    ConfusionMatrixDisplay.from_estimator(pipeline, X_test, y_test, cmap=plt.cm.Blues)\n",
        "    plt.title(f\"Confusion Matrix - {name}\")\n",
        "    plt.show()\n",
        "\n",
        "    results[name] = {\n",
        "        \"model\": pipeline,\n",
        "        \"report\": classification_report(y_test, y_pred, output_dict=True),\n",
        "        \"proba\": y_proba,\n",
        "        \"preds\": y_pred\n",
        "    }\n",
        "\n",
        "print(\"\\nAll models have been trained and evaluated.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qn2nwPjQ5Qc"
      },
      "outputs": [],
      "source": [
        "# Anomaly Alert System with Voting\n",
        "def alert_intrusions():\n",
        "    print(\"\\nANOMALY ALERTS using Voting System\")\n",
        "    print(\"Scanning predictions for detected anomalies...\")\n",
        "    \n",
        "    # Initialize counters for each sample\n",
        "    sample_votes = np.zeros(len(y_test))\n",
        "    sample_confidences = np.zeros(len(y_test))\n",
        "    \n",
        "    # Collect votes and confidences from each model\n",
        "    for model_name, model_info in results.items():\n",
        "        for i, (pred, prob) in enumerate(zip(model_info['preds'], \n",
        "                                           model_info['proba'] if model_info['proba'] is not None \n",
        "                                           else np.zeros((len(y_test), 2)))):\n",
        "            if pred == 1:\n",
        "                sample_votes[i] += 1\n",
        "                sample_confidences[i] += prob[1] if model_info['proba'] is not None else 1\n",
        "    \n",
        "    # Calculate average confidence for each sample\n",
        "    sample_confidences = sample_confidences / len(results)\n",
        "    \n",
        "    # Count confirmed anomalies\n",
        "    count = 0\n",
        "    for i, (votes, conf) in enumerate(zip(sample_votes, sample_confidences)):\n",
        "        # An anomaly is confirmed if majority of models predict it (votes > len(models)/2)\n",
        "        # and average confidence is above threshold\n",
        "        if votes > len(models)/2 and conf >= 0.75:\n",
        "            count += 1\n",
        "            print(f\"\\nALERT #{count}\")\n",
        "            print(\"-------------------------\")\n",
        "            print(f\"Sample Index      : {i}\")\n",
        "            print(f\"Actual Label      : {y_test.iloc[i]}\")\n",
        "            print(f\"Votes for Anomaly : {votes}/{len(models)}\")\n",
        "            print(f\"Average Confidence: {conf:.2%}\")\n",
        "            print(\"-------------------------\")\n",
        "\n",
        "    if count == 0:\n",
        "        print(\"No confirmed anomalies detected in the current test set\")\n",
        "    else:\n",
        "        print(f\"\\nTotal Confirmed Anomalies: {count}\")\n",
        "\n",
        "# Run the voting-based anomaly detection\n",
        "alert_intrusions()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
